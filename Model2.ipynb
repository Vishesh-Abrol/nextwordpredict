{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cc053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a786c111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line:  roject gutenberg's the adventures of sherlock holmes by arthur conan doyle this ebook is for the use\n",
      "last line:  lapped the hat upon his head it came right over the forehead and settled upon the bridge of his nose\n",
      "Total words in this:  52217\n"
     ]
    }
   ],
   "source": [
    "file = open('book3.txt')   #processed book\n",
    "data = file.read()\n",
    "data = data.replace('\\ufeff', \"\")\n",
    "data = data[1:-1]\n",
    "print(\"first line: \" , data[:100])\n",
    "print(\"last line: \", data[-100:])\n",
    "print(\"Total words in this: \",len(data.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66cc3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])   #see we passing a list here important \n",
    "\n",
    "pickle.dump(tokenizer, open('M2tokenizer.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]  #see here texts to seq returns a list \n",
    "\n",
    "# fit_on_texts Updates internal vocabulary based on a list of texts. \n",
    "# This method creates the vocabulary index based on word frequency. \n",
    "# So if you give it something like, \"The cat sat on the mat.\" \n",
    "# It will create a dictionary s.t. word_index[\"the\"] = 1; word_index[\"cat\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91b490c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5834\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  #number of unique words as the list is 0 based index add 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eae8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"roject gutenberg's the\"]\n",
      "[2894, 2895, 1]\n",
      "['adventures']\n",
      "1003\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(0 , len(sequence_data)-4):\n",
    "    word = []\n",
    "    for j in range(i , i+3):   \n",
    "        word.append(sequence_data[j])\n",
    "    X.append(word)\n",
    "    Y.append(sequence_data[i+3])\n",
    "\n",
    "\n",
    "print(tokenizer.sequences_to_texts([X[0]]))\n",
    "print(X[0])\n",
    "print(tokenizer.sequences_to_texts([[Y[0]]]))\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adad573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = to_categorical(Y, num_classes=vocab_size)\n",
    "print(Y[0])\n",
    "print(Y[0][1546])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70ced8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3, 10)             58340     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 3, 1000)           4044000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1000)              8004000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5834)              5839834   \n",
      "=================================================================\n",
      "Total params: 18,947,174\n",
      "Trainable params: 18,947,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 10, input_length=3),\n",
    "    LSTM(1000, return_sequences=True),\n",
    "    LSTM(1000),\n",
    "    Dense(1000, activation=\"relu\"),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8aa8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c582d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "823/823 [==============================] - 255s 306ms/step - loss: 6.4617 - accuracy: 0.0581\n",
      "Epoch 2/60\n",
      "823/823 [==============================] - 242s 294ms/step - loss: 5.9411 - accuracy: 0.0820\n",
      "Epoch 3/60\n",
      "823/823 [==============================] - 242s 294ms/step - loss: 5.5858 - accuracy: 0.1007\n",
      "Epoch 4/60\n",
      "823/823 [==============================] - 238s 289ms/step - loss: 5.3210 - accuracy: 0.1126\n",
      "Epoch 5/60\n",
      "823/823 [==============================] - 235s 285ms/step - loss: 5.0979 - accuracy: 0.1252\n",
      "Epoch 6/60\n",
      "823/823 [==============================] - 248s 301ms/step - loss: 4.8910 - accuracy: 0.1349\n",
      "Epoch 7/60\n",
      "823/823 [==============================] - 239s 291ms/step - loss: 4.6781 - accuracy: 0.1475\n",
      "Epoch 8/60\n",
      "823/823 [==============================] - 240s 292ms/step - loss: 4.4509 - accuracy: 0.1574\n",
      "Epoch 9/60\n",
      "823/823 [==============================] - 238s 289ms/step - loss: 4.1911 - accuracy: 0.1718\n",
      "Epoch 10/60\n",
      "823/823 [==============================] - 230s 279ms/step - loss: 3.9092 - accuracy: 0.1895\n",
      "Epoch 11/60\n",
      "823/823 [==============================] - 238s 289ms/step - loss: 3.6059 - accuracy: 0.2190\n",
      "Epoch 12/60\n",
      "823/823 [==============================] - 257s 312ms/step - loss: 3.3136 - accuracy: 0.2566\n",
      "Epoch 13/60\n",
      "823/823 [==============================] - 264s 321ms/step - loss: 3.0405 - accuracy: 0.2966\n",
      "Epoch 14/60\n",
      "823/823 [==============================] - 259s 314ms/step - loss: 2.7799 - accuracy: 0.3383\n",
      "Epoch 15/60\n",
      "823/823 [==============================] - 244s 296ms/step - loss: 2.5376 - accuracy: 0.3829\n",
      "Epoch 16/60\n",
      "823/823 [==============================] - 241s 293ms/step - loss: 2.3182 - accuracy: 0.4231\n",
      "Epoch 17/60\n",
      "823/823 [==============================] - 247s 300ms/step - loss: 2.0951 - accuracy: 0.4670\n",
      "Epoch 18/60\n",
      "823/823 [==============================] - 240s 292ms/step - loss: 1.8865 - accuracy: 0.5109\n",
      "Epoch 19/60\n",
      "823/823 [==============================] - 230s 279ms/step - loss: 1.6840 - accuracy: 0.5564\n",
      "Epoch 20/60\n",
      "823/823 [==============================] - 230s 279ms/step - loss: 1.4942 - accuracy: 0.6023\n",
      "Epoch 21/60\n",
      "823/823 [==============================] - 231s 281ms/step - loss: 1.3149 - accuracy: 0.6458\n",
      "Epoch 22/60\n",
      "823/823 [==============================] - 235s 285ms/step - loss: 1.1522 - accuracy: 0.6859\n",
      "Epoch 23/60\n",
      "823/823 [==============================] - 248s 301ms/step - loss: 1.0085 - accuracy: 0.7250\n",
      "Epoch 24/60\n",
      "823/823 [==============================] - 234s 285ms/step - loss: 0.8959 - accuracy: 0.7565\n",
      "Epoch 25/60\n",
      "823/823 [==============================] - 238s 289ms/step - loss: 0.7986 - accuracy: 0.7833\n",
      "Epoch 26/60\n",
      "823/823 [==============================] - 245s 298ms/step - loss: 0.7114 - accuracy: 0.8099\n",
      "Epoch 27/60\n",
      "823/823 [==============================] - 253s 307ms/step - loss: 0.6561 - accuracy: 0.8218\n",
      "Epoch 28/60\n",
      "823/823 [==============================] - 260s 316ms/step - loss: 0.6137 - accuracy: 0.8355\n",
      "Epoch 29/60\n",
      "823/823 [==============================] - 259s 315ms/step - loss: 0.5706 - accuracy: 0.8437\n",
      "Epoch 30/60\n",
      "823/823 [==============================] - 256s 310ms/step - loss: 0.5388 - accuracy: 0.8515\n",
      "Epoch 31/60\n",
      "823/823 [==============================] - 254s 308ms/step - loss: 0.5250 - accuracy: 0.8549\n",
      "Epoch 32/60\n",
      "823/823 [==============================] - 244s 296ms/step - loss: 0.5000 - accuracy: 0.8595\n",
      "Epoch 33/60\n",
      "823/823 [==============================] - 243s 295ms/step - loss: 0.4787 - accuracy: 0.8620\n",
      "Epoch 34/60\n",
      "823/823 [==============================] - 244s 297ms/step - loss: 0.4673 - accuracy: 0.8647\n",
      "Epoch 35/60\n",
      "823/823 [==============================] - 230s 280ms/step - loss: 0.4534 - accuracy: 0.8664\n",
      "Epoch 36/60\n",
      "823/823 [==============================] - 231s 280ms/step - loss: 0.4336 - accuracy: 0.8689\n",
      "Epoch 37/60\n",
      "823/823 [==============================] - 229s 279ms/step - loss: 0.4268 - accuracy: 0.8696\n",
      "Epoch 38/60\n",
      "823/823 [==============================] - 229s 278ms/step - loss: 0.4164 - accuracy: 0.8719\n",
      "Epoch 39/60\n",
      "823/823 [==============================] - 229s 278ms/step - loss: 0.4077 - accuracy: 0.8729\n",
      "Epoch 40/60\n",
      "823/823 [==============================] - 244s 296ms/step - loss: 0.4075 - accuracy: 0.8703\n",
      "Epoch 41/60\n",
      "823/823 [==============================] - 240s 292ms/step - loss: 0.3936 - accuracy: 0.8731\n",
      "Epoch 42/60\n",
      "823/823 [==============================] - 245s 298ms/step - loss: 0.3817 - accuracy: 0.8751\n",
      "Epoch 43/60\n",
      "823/823 [==============================] - 262s 319ms/step - loss: 0.3725 - accuracy: 0.8762\n",
      "Epoch 44/60\n",
      "823/823 [==============================] - 243s 295ms/step - loss: 0.3789 - accuracy: 0.8735\n",
      "Epoch 45/60\n",
      "823/823 [==============================] - 233s 283ms/step - loss: 0.3703 - accuracy: 0.8730\n",
      "Epoch 46/60\n",
      "823/823 [==============================] - 243s 296ms/step - loss: 0.3627 - accuracy: 0.8757\n",
      "Epoch 47/60\n",
      "823/823 [==============================] - 240s 292ms/step - loss: 0.3535 - accuracy: 0.8772\n",
      "Epoch 48/60\n",
      "823/823 [==============================] - 242s 294ms/step - loss: 0.3461 - accuracy: 0.8772\n",
      "Epoch 49/60\n",
      "823/823 [==============================] - 241s 293ms/step - loss: 0.3463 - accuracy: 0.8765\n",
      "Epoch 50/60\n",
      "823/823 [==============================] - 263s 320ms/step - loss: 0.3382 - accuracy: 0.8770\n",
      "Epoch 51/60\n",
      "823/823 [==============================] - 253s 307ms/step - loss: 0.3412 - accuracy: 0.8762\n",
      "Epoch 52/60\n",
      "823/823 [==============================] - 248s 301ms/step - loss: 0.3281 - accuracy: 0.8788\n",
      "Epoch 53/60\n",
      "823/823 [==============================] - 238s 290ms/step - loss: 0.3259 - accuracy: 0.8775\n",
      "Epoch 54/60\n",
      "823/823 [==============================] - 234s 285ms/step - loss: 0.3239 - accuracy: 0.8784\n",
      "Epoch 55/60\n",
      "823/823 [==============================] - 235s 285ms/step - loss: 0.3220 - accuracy: 0.8780\n",
      "Epoch 56/60\n",
      "823/823 [==============================] - 235s 286ms/step - loss: 0.3169 - accuracy: 0.8780\n",
      "Epoch 57/60\n",
      "823/823 [==============================] - 238s 289ms/step - loss: 0.3229 - accuracy: 0.8762\n",
      "Epoch 58/60\n",
      "823/823 [==============================] - 242s 294ms/step - loss: 0.3066 - accuracy: 0.8790\n",
      "Epoch 59/60\n",
      "823/823 [==============================] - 250s 304ms/step - loss: 0.3029 - accuracy: 0.8793\n",
      "Epoch 60/60\n",
      "823/823 [==============================] - 250s 304ms/step - loss: 0.3029 - accuracy: 0.8788\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X , Y , epochs=60, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86d19f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(history.history, open('M2history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28750398",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('m2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0aa589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
